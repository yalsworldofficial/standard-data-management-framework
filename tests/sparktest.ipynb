{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0f59d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d33526e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "26/01/28 10:38:37 WARN Utils: Your hostname, DESKTOP-8BFCOG4 resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "26/01/28 10:38:37 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/hando/dev/standard-data-management-framework/.venv/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/hando/.ivy2/cache\n",
      "The jars for the packages stored in: /home/hando/.ivy2/jars\n",
      "io.delta#delta-spark_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-32d5018f-9363-4b4a-83e2-5402a3442c5a;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-spark_2.12;3.1.0 in central\n",
      "\tfound io.delta#delta-storage;3.1.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      ":: resolution report :: resolve 103ms :: artifacts dl 4ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-spark_2.12;3.1.0 from central in [default]\n",
      "\tio.delta#delta-storage;3.1.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-32d5018f-9363-4b4a-83e2-5402a3442c5a\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/4ms)\n",
      "26/01/28 10:38:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"sdmf\")\n",
    "    .enableHiveSupport()\n",
    "    .config(\n",
    "        \"spark.jars.packages\",\n",
    "        \"io.delta:delta-spark_2.12:3.1.0\"\n",
    "    )\n",
    "    .config(\n",
    "        \"spark.sql.extensions\",\n",
    "        \"io.delta.sql.DeltaSparkSessionExtension\"\n",
    "    )\n",
    "    .config(\n",
    "        \"spark.sql.catalog.spark_catalog\",\n",
    "        \"org.apache.spark.sql.delta.catalog.DeltaCatalog\"\n",
    "    )\n",
    "    .getOrCreate()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae7af12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/24 17:46:55 WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider delta. Persisting data source table `spark_catalog`.`demo`.`customers` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.\n"
     ]
    }
   ],
   "source": [
    "df = spark.range(1, 101).toDF(\"row_id\")\n",
    "df = (\n",
    "    df\n",
    "    .withColumn(\"alpha3_b\", expr(\"concat('USA', row_id)\"))\n",
    "    .withColumn(\"alpha3_t\", expr(\"concat('US', row_id)\"))\n",
    "    .withColumn(\"alpha2\", expr(\"substring('US', 1, 2)\"))\n",
    "    .withColumn(\n",
    "        \"english\",\n",
    "        expr(\"\"\"\n",
    "            CASE\n",
    "                WHEN row_id % 4 = 0 THEN 'United States'\n",
    "                WHEN row_id % 4 = 1 THEN 'Germany'\n",
    "                WHEN row_id % 4 = 2 THEN 'India'\n",
    "                ELSE 'Canada'\n",
    "            END\n",
    "        \"\"\")\n",
    "    )\n",
    "    .drop(\"row_id\")\n",
    ")\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS demo\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS demo.customers\")\n",
    "df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"demo.customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9159a625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.tableExists(\"demo.customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b91d653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "import string\n",
    "\n",
    "# Function to generate random values\n",
    "def random_alpha3():\n",
    "    return ''.join(random.choices(string.ascii_uppercase, k=3))\n",
    "\n",
    "def random_alpha2():\n",
    "    return ''.join(random.choices(string.ascii_uppercase, k=2))\n",
    "\n",
    "def random_english_word():\n",
    "    return ''.join(random.choices(string.ascii_lowercase, k=6))\n",
    "\n",
    "# Generate random values\n",
    "alpha3_b = random_alpha3()\n",
    "alpha3_t = random_alpha3()\n",
    "alpha2 = random_alpha2()\n",
    "english = random_english_word()\n",
    "\n",
    "# Insert into Spark SQL\n",
    "query = f\"\"\"\n",
    "INSERT INTO demo.customers (alpha3_b, alpha3_t, alpha2, english)\n",
    "VALUES ('{alpha3_b}', '{alpha3_t}', '{alpha2}', '{english}')\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "021fb18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+------+-------------+\n",
      "|alpha3_b|alpha3_t|alpha2|english      |\n",
      "+--------+--------+------+-------------+\n",
      "|USA96   |US96    |US    |United States|\n",
      "|USA97   |US97    |US    |Germany      |\n",
      "|USA98   |US98    |US    |India        |\n",
      "|USA99   |US99    |US    |Canada       |\n",
      "|USA100  |US100   |US    |United States|\n",
      "|USA91   |US91    |US    |Canada       |\n",
      "|USA92   |US92    |US    |United States|\n",
      "|USA93   |US93    |US    |Germany      |\n",
      "|USA94   |US94    |US    |India        |\n",
      "|USA95   |US95    |US    |Canada       |\n",
      "|USA41   |US41    |US    |Germany      |\n",
      "|USA42   |US42    |US    |India        |\n",
      "|USA43   |US43    |US    |Canada       |\n",
      "|USA44   |US44    |US    |United States|\n",
      "|USA45   |US45    |US    |Germany      |\n",
      "|USA26   |US26    |US    |India        |\n",
      "|USA27   |US27    |US    |Canada       |\n",
      "|USA28   |US28    |US    |United States|\n",
      "|USA29   |US29    |US    |Germany      |\n",
      "|USA30   |US30    |US    |India        |\n",
      "|USA21   |US21    |US    |Germany      |\n",
      "|USA22   |US22    |US    |India        |\n",
      "|USA23   |US23    |US    |Canada       |\n",
      "|USA24   |US24    |US    |United States|\n",
      "|USA25   |US25    |US    |Germany      |\n",
      "|USA31   |US31    |US    |Canada       |\n",
      "|USA32   |US32    |US    |United States|\n",
      "|USA33   |US33    |US    |Germany      |\n",
      "|USA34   |US34    |US    |India        |\n",
      "|USA35   |US35    |US    |Canada       |\n",
      "|USA46   |US46    |US    |India        |\n",
      "|USA47   |US47    |US    |Canada       |\n",
      "|USA48   |US48    |US    |United States|\n",
      "|USA49   |US49    |US    |Germany      |\n",
      "|USA50   |US50    |US    |India        |\n",
      "|USA16   |US16    |US    |United States|\n",
      "|USA17   |US17    |US    |Germany      |\n",
      "|USA18   |US18    |US    |India        |\n",
      "|USA19   |US19    |US    |Canada       |\n",
      "|USA20   |US20    |US    |United States|\n",
      "|USA61   |US61    |US    |Germany      |\n",
      "|USA62   |US62    |US    |India        |\n",
      "|USA63   |US63    |US    |Canada       |\n",
      "|USA64   |US64    |US    |United States|\n",
      "|USA65   |US65    |US    |Germany      |\n",
      "|USA71   |US71    |US    |Canada       |\n",
      "|USA72   |US72    |US    |United States|\n",
      "|USA73   |US73    |US    |Germany      |\n",
      "|USA74   |US74    |US    |India        |\n",
      "|USA75   |US75    |US    |Canada       |\n",
      "|USA81   |US81    |US    |Germany      |\n",
      "|USA82   |US82    |US    |India        |\n",
      "|USA83   |US83    |US    |Canada       |\n",
      "|USA84   |US84    |US    |United States|\n",
      "|USA85   |US85    |US    |Germany      |\n",
      "|USA66   |US66    |US    |India        |\n",
      "|USA67   |US67    |US    |Canada       |\n",
      "|USA68   |US68    |US    |United States|\n",
      "|USA69   |US69    |US    |Germany      |\n",
      "|USA70   |US70    |US    |India        |\n",
      "|USA51   |US51    |US    |Canada       |\n",
      "|USA52   |US52    |US    |United States|\n",
      "|USA53   |US53    |US    |Germany      |\n",
      "|USA54   |US54    |US    |India        |\n",
      "|USA55   |US55    |US    |Canada       |\n",
      "|USA11   |US11    |US    |Canada       |\n",
      "|USA12   |US12    |US    |United States|\n",
      "|USA13   |US13    |US    |Germany      |\n",
      "|USA14   |US14    |US    |India        |\n",
      "|USA15   |US15    |US    |Canada       |\n",
      "|USA86   |US86    |US    |India        |\n",
      "|USA87   |US87    |US    |Canada       |\n",
      "|USA88   |US88    |US    |United States|\n",
      "|USA89   |US89    |US    |Germany      |\n",
      "|USA90   |US90    |US    |India        |\n",
      "|USA36   |US36    |US    |United States|\n",
      "|USA37   |US37    |US    |Germany      |\n",
      "|USA38   |US38    |US    |India        |\n",
      "|USA39   |US39    |US    |Canada       |\n",
      "|USA40   |US40    |US    |United States|\n",
      "|USA56   |US56    |US    |United States|\n",
      "|USA57   |US57    |US    |Germany      |\n",
      "|USA58   |US58    |US    |India        |\n",
      "|USA59   |US59    |US    |Canada       |\n",
      "|USA60   |US60    |US    |United States|\n",
      "|USA76   |US76    |US    |United States|\n",
      "|USA77   |US77    |US    |Germany      |\n",
      "|USA78   |US78    |US    |India        |\n",
      "|USA79   |US79    |US    |Canada       |\n",
      "|USA80   |US80    |US    |United States|\n",
      "|USA6    |US6     |US    |India        |\n",
      "|USA7    |US7     |US    |Canada       |\n",
      "|USA8    |US8     |US    |United States|\n",
      "|USA9    |US9     |US    |Germany      |\n",
      "|USA10   |US10    |US    |India        |\n",
      "|USA1    |US1     |US    |Germany      |\n",
      "|USA2    |US2     |US    |India        |\n",
      "|USA3    |US3     |US    |Canada       |\n",
      "|USA4    |US4     |US    |United States|\n",
      "|USA5    |US5     |US    |Germany      |\n",
      "|OKQ     |AEV     |QG    |okdgor       |\n",
      "+--------+--------+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from demo.customers\").show(10000000, truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
